import pandas as pd
import numpy as np
import os
import gzip
from functools import reduce
import scipy.stats as st
import statsmodels.stats.multitest as multi

cohort_nms= ['harvestm12', 'harvestm24','rotterdam1', 'rotterdam2', 'normentfeb', 'normentmay']
smpl_nms= ['maternal','paternal', 'fetal']
batch_nms= ['m12', 'm24']
CHR_nms= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12 ,13 ,14 ,15 ,16 ,17 ,18 ,19 ,20 ,21 ,22]

# Other arguments:

pruning_nms= ['none', 'soft', 'moderate']

dens_nms= [5]
SNP_nms= [15, 25, 50, 75, 100, 150, 200, 300, 400]
length_nms= [0.0000001]
het_nms= [0, 1]
GAP_nms= [5]

dens_bp= [5000]
SNP_bp= [15, 25, 50, 75, 100, 150, 200, 300, 400]
length_bp= [0.0000001]
het_bp= [0, 1]
GAP_bp= [5000]

# Functions

def isfloat(str):
    try:
        float(str)
        return True
    except ValueError:
        return False


rule extract_HC:
	'List of variants for extracting genotype.'
	input:
		'/mnt/work/pol/ROH/results/surv_spont_{sample}',
                '/mnt/work/pol/ROH/results/{sample}/eff_ROH.txt'
	output:
		'/mnt/work/pol/ROH/results/misc/HC_toextract_{sample}'
	run:
		d= pd.read_csv(input[0], sep= '\t', header= 0)
		with open(input[1]) as f:
			eff= sum([int(line.strip()) for line in f])
		if d.shape[0]== 0:
			open(output[0], 'a').close()
		else:
			d['chr']= d.chr.astype(int)
			d= d.loc[d.pvalue< 0.05/ eff, :]
			d= d[['chr', 'pos1', 'pos2']]
			d= d.applymap(np.int64)
			d['chr']= d.chr.astype(str)
			d['chr']= np.where(d.chr== '23', 'X', d.chr)
			d.sort_values(['chr', 'pos1'], inplace= True)
			d.to_csv(output[0], sep= '\t', index= False, header= False)

rule extract_vcf_samples:
        'Extract samples id included in the VCF file, for each batch.'
        input:
		'/mnt/archive/MOBAGENETICS/genotypes-base/imputed/all/vcf/1.vcf.gz'
	output:
                temp('/mnt/work/pol/ROH/genotypes/imputed/vcf_ids')
	run:
                shell("set +o pipefail; zgrep -v '##' {input[0]} | head -1 | cut -f10- | sed 's/\\t/\\n/g'  > {output[0]} ")

rule extract_samples:
        'Samples for filtering VCF files.'
        input:
                '/mnt/work/pol/ROH/pheno/runs_mfr_{sample}.txt',
                '/mnt/work/pol/ROH/genotypes/imputed/vcf_ids'
        output:
                '/mnt/work/pol/ROH/genotypes/imputed/{sample}_ids_toextract'
        run:
                x= [line.strip() for line in open(input[1], 'r')]
		d= pd.read_csv(input[0], sep= '\t', header= 0)
		d= d.loc[d['IID'].isin(x)]
                d.drop_duplicates(subset= ['IID'], inplace= True)
                d.to_csv(output[0], header= False, columns= ['IID'], index= False, sep= '\t')

rule extract_GT:
        'Extract genotype for HC segments.'
        input:
                '/mnt/work/pol/ROH/results/misc/HC_toextract_{sample}',
                '/mnt/work/pol/ROH/genotypes/imputed/{sample}_ids_toextract',
		'/mnt/archive/MOBAGENETICS/genotypes-base/imputed/all/vcf/{CHR}.vcf.gz'
	output:
                temp('/mnt/work/pol/ROH/genotypes/GT/{sample}_gt{CHR}_HC')
	run:
		if os.stat(input[0]).st_size > 0: shell("~/soft/bcftools-1.9/bin/bcftools query -S {input[1]} -R {input[0]} -f '%CHROM\t%POS\t%REF\t%ALT[\t%GT]\n' {input[2]} -o {output[0]}")
		if os.stat(input[0]).st_size == 0: open(output[0], 'a').close()

rule concat_GT:
        'Concat GT form all chromosomes.'
        input:
                expand('/mnt/work/pol/ROH/genotypes/GT/{{sample}}_gt{CHR}_HC', CHR= CHR_nms)
        output:
                temp('/mnt/work/pol/ROH/genotypes/GT/{sample}_HC_temp')
        shell:
                'cat {input} > {output[0]}'

rule samples_and_bed_file:
	input:
		'/mnt/work/pol/ROH/GNOMAD/LOF.txt',
		'/mnt/work/pol/ROH/genotypes/maps/{sample}/top_segments_{sample}.txt',
		'/mnt/work/pol/ROH/results/misc/HC_toextract_{sample}'
	output:
		'/mnt/work/pol/ROH/genotypes/lof/{sample}_top_segments_ids.txt',
		'/mnt/work/pol/ROH/genotypes/lof/{sample}_top_segments.txt'
	run:
		if os.stat(input[1]).st_size > 0:
			lof= pd.read_csv(input[0], sep= '\t', header= None, names= ['chr', 'pos', 'lof'])
			d= pd.read_csv(input[1], sep= '\t', header= 0)
			d= d.iloc[:,2:].T
			d['IID']= d.index
			d= d.loc[d[0]>0, :]
			d.to_csv(output[0], sep= '\t', header= False, index= False, columns= ['IID'])
			d= pd.read_csv(input[2], header= None, names= ['chr', 'pos1', 'pos2'], sep= '\t')
			d= pd.merge(d, lof, on= 'chr')
			d= d.loc[(d.pos>= d.pos1) & (d.pos<= d.pos2), :]
			d= d.loc[:,['chr', 'pos', 'pos']]
			d.to_csv(output[1], sep= '\t', header=False, index= False)
		else:
			open(output[0], 'a').close()
			open(output[1], 'a').close()

rule extract_GT_missense:
	''
	input:
		'/mnt/archive/MOBAGENETICS/genotypes-base/imputed/all/vcf/{CHR}.vcf.gz',
		'/mnt/work/pol/ROH/genotypes/lof/{sample}_top_segments_ids.txt',
		'/mnt/work/pol/ROH/genotypes/lof/{sample}_top_segments.txt'
	output:
		temp('/mnt/work/pol/ROH/genotypes/lof/geno/temp_top_missense_{sample}_{CHR}.txt')
	run:
		if os.stat(input[1]).st_size > 0: shell("~/soft/bcftools-1.9/bin/bcftools query -S {input[1]} -R {input[2]} -f '%CHROM\t%POS\t%REF\t%ALT[\t%GT]\n' {input[0]} -o {output[0]}")
		if os.stat(input[1]).st_size == 0: open(output[0], 'a').close()

rule concat_missenes_GT:
	''
	input:
		expand('/mnt/work/pol/ROH/genotypes/lof/geno/temp_top_missense_{{sample}}_{CHR}.txt', CHR= CHR_nms)
	output:
		'/mnt/work/pol/ROH/genotypes/lof/geno/top_missense_{sample}.txt'
	shell:
		'cat {input} > {output[0]}'
