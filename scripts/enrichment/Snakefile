import pandas as pd
import numpy as np
import os
import gzip
from functools import reduce
import scipy.stats as st
import statsmodels.stats.multitest as multi

cohort_nms= ['harvestm12', 'harvestm24','rotterdam1', 'rotterdam2', 'normentfeb', 'normentmay']
smpl_nms= ['maternal','paternal', 'fetal']
batch_nms= ['m12', 'm24']
CHR_nms= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12 ,13 ,14 ,15 ,16 ,17 ,18 ,19 ,20 ,21 ,22]

# Other arguments:

pruning_nms= ['none', 'soft', 'moderate', 'hard']

dens_nms= [5]
SNP_nms= [15, 25, 50, 75, 100, 150, 200, 350, 500]
length_nms= [0.0000001]
het_nms= [0, 1]
GAP_nms= [5]

dens_bp= [5000]
SNP_bp= [15, 25, 50, 75, 100, 150, 200, 350, 500]
length_bp= [0.0000001]
het_bp= [0, 1]
GAP_bp= [5000]

# Functions

def isfloat(str):
    try:
        float(str)
        return True
    except ValueError:
        return False

rule OMIM_bp_to_cM:
        'Convert physical to genomic distance, filter recessive and dominant.'
        input:
                '/mnt/work/pol/refdata/OMIM/hg19/genemap2_hg19.txt',
                '/mnt/work/pol/ROH/1KG/1000GP_Phase3/genetic_map_combined_b37.txt'
        output:
                temp('/mnt/work/pol/ROH/results/OMIM_recessive.txt'),
                temp('/mnt/work/pol/ROH/results/OMIM_dominant.txt')
        script:
                'scripts/enrichment/OMIM_bp_to_cM.py'

rule obtain_random_segments:
        'Obtain random NC segments with similar size to those with HC.'
        input:
                '/mnt/work/pol/ROH/results/HC_{sample}_cox_spont',
                '/mnt/work/pol/ROH/results/NC_{sample}_cox_spont'
        output:
                '/mnt/work/pol/ROH/GNOMAD/geno/HC_toextract_{sample}.txt',
                '/mnt/work/pol/ROH/GNOMAD/geno/NC_toextract_{sample}.txt',
                '/mnt/work/pol/ROH/results/HC_and_NC_cox_spont_{sample}.txt'
        run:
                d= pd.read_csv(input[0], sep= '\t', header= 0)
                df= pd.read_csv(input[1], sep= '\t', header= 0)
                d[['chr', 'cM1', 'cM2']]= d['segment'].str.split(':',expand=True)
                df[['chr', 'cM1', 'cM2']]= df['segment'].str.split(':',expand=True)
                d[['chr', 'cM1', 'cM2']]= d[['chr', 'cM1', 'cM2']].astype(float)
                df[['chr', 'cM1', 'cM2']]= df[['chr', 'cM1', 'cM2']].astype(float)
                df.columns= df.columns + '_NC'
                d['cM_dif']= d['cM2'] - d['cM1']
                df['cM_dif_NC']= df['cM2_NC'] - df['cM1_NC']
                a = df.cM_dif_NC.values
                bh = d.cM_dif.values + 0.05 * d.cM_dif.values
                bl = d.cM_dif.values - 0.05 * d.cM_dif.values
                i, j = np.where((a[:, None] >= bl) & (a[:, None] <= bh))
                newdf= pd.DataFrame(np.column_stack([df.values[i], d.values[j]]), columns=df.columns.append(d.columns))
                x= newdf.groupby('segment').apply(lambda x: x.sample(200, replace= True)).reset_index(drop=True)
                x[['chr_NC', 'cM1_NC', 'cM2_NC', 'chr', 'cM1', 'cM2']]= x[['chr_NC', 'cM1_NC', 'cM2_NC', 'chr', 'cM1', 'cM2']].astype(float)
                x[['chr', 'pos1', 'pos2', 'chr_NC', 'pos1_NC', 'pos2_NC']]= x[['chr', 'pos1', 'pos2', 'chr_NC', 'pos1_NC', 'pos2_NC']].apply(lambda x: x.astype(int))
                x.sort_values(by= ['chr', 'pos1'], ascending= True, inplace= True)
                df= x.drop_duplicates(subset= ['chr', 'pos1'], keep= 'first')
                df.to_csv(output[0], sep= '\t', columns= ['chr', 'pos1', 'pos2'], header= False, index= False)
                df= x.drop_duplicates(subset= ['chr_NC', 'pos1_NC'], keep= 'first')
                df.sort_values(by= ['chr_NC', 'pos1_NC'], ascending= True, inplace= True)
                df.to_csv(output[1], sep= '\t', columns= ['chr_NC', 'pos1_NC', 'pos2_NC'], header= False, index= False)
                x.to_csv(output[2], sep='\t', header= True, index= False)

rule OMIM_enrichment:
        'Enrichment in OMIM genes (recessive and dominant only).'
        input:
                '/mnt/work/pol/ROH/results/HC_and_NC_cox_spont_{sample}.txt',
                '/mnt/work/pol/ROH/results/OMIM_{model}.txt'
        output:
                '/mnt/work/pol/ROH/results/enrichment/OMIM_{model}_{sample}.txt'
        script:
                'scripts/enrichment/OMIM_enrichment.py'

rule download_GNOMAD:
        'Download GNOMAD genomes.'
        output:
                temp('/mnt/work/pol/ROH/GNOMAD/geno/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.gz'),
                temp('/mnt/work/pol/ROH/GNOMAD/geno/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.gz.tbi')
        params:
                'https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.bgz',
                'https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.bgz.tbi'
        shell:
                '''
                wget -O {output[0]} {params[0]}
                wget -O {output[1]} {params[1]}
                '''

rule extract_GNOMAD:
        'Use bcftools to filter GNOMAD'
        input:
                '/mnt/work/pol/ROH/GNOMAD/geno/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.gz',
                '/mnt/work/pol/ROH/GNOMAD/geno/{conf}_toextract_{sample}.txt',
                '/mnt/work/pol/ROH/GNOMAD/geno/gnomad.genomes.r2.1.1.sites.{CHR}.vcf.gz.tbi'
        output:
                temp('/mnt/work/pol/ROH/GNOMAD/geno/gnomad.{CHR}_{conf}_{sample}_temp')
        shell:
                "tabix -R {input[1]} {input[0]} > {output[0]}"

rule process_GNOMAD:
        'Extract missense and loss-of-function variants.'
        input:
                '/mnt/work/pol/ROH/GNOMAD/geno/gnomad.{CHR}_{conf}_{sample}_temp'
        output:
                temp('/mnt/work/pol/ROH/GNOMAD/annotation/filtered_GNOMAD_{conf}_{sample}_{CHR}.txt')

        shell:
                """
                set +o pipefail;
                paste <(cut -f1,2 {input[0]}) <(awk -Fvep= '{{ print $NF }}' {input[0]})| grep -e 'stop_lost' -e 'stop_gained' -e 'start_lost' -e 'inframe_insertion' -e 'inframe_deletion' -e 'frameshift' -e 'splice_donor' -e 'splice_acceptor' -e 'missense' -e 'transcript_ablation' -e 'protein_altering' -e 'regulatory_region_ablation' -e 'transcript_amplification' | sed 's/|/\t/g' | cut -f1,2,4 > {output[0]}
                """

rule concat_GNOMAD:
        ''
        input:
                expand('/mnt/work/pol/ROH/GNOMAD/annotation/filtered_GNOMAD_{{conf}}_{{sample}}_{CHR}.txt', CHR= CHR_nms)
        output:
                '/mnt/work/pol/ROH/GNOMAD/annotation/filtered_GNOMAD_{conf}_{sample}.txt'
        shell:
                'cat {input} > {output[0]}'

rule combine_GNOMAD_annotation:
        'Combine GNOMAD annotation and cox segmental results.'
        input:
                '/mnt/work/pol/ROH/GNOMAD/annotation/filtered_GNOMAD_{conf}_{sample}.txt',
                '/mnt/work/pol/ROH/GNOMAD/geno/{conf}_toextract_{sample}.txt'
        output:
                '/mnt/work/pol/ROH/GNOMAD/annotation/GNOMAD_{sample}_{conf}_mod.txt',
                '/mnt/work/pol/ROH/GNOMAD/annotation/GNOMAD_{sample}_{conf}_high.txt'
        run:
                moderate= ['inframe_deletion', 'inframe_insertion', 'missense_variant', 'protein_altering_variant', 'regulatory_region_ablation']
                df= pd.read_csv(input[0], sep= '\t', header= None, names= ['chr', 'pos', 'VEP'])
                d= pd.read_csv(input[1], sep= '\t', header= None, names= ['chr', 'pos1', 'pos2'])
                mod= list()
                high= list()
                for CHR in set(df.chr):
                        temp_df= df[df.chr== CHR]
                        temp_d= d[d.chr== CHR]
                        a = temp_df.pos
                        bh = temp_d.pos2.values
                        bl = temp_d.pos1.values
                        i, j = np.where((a[:, None] >= bl) & (a[:, None] <= bh))
                        x= pd.DataFrame(np.column_stack([temp_df.values[i], temp_d.values[j]]), columns=temp_df.columns.append(temp_d.columns))
                        mod= x[x.VEP.str.contains('|'.join(moderate))]
                        high= x[~x.VEP.str.contains('|'.join(moderate))]
                        mod_list.append(mod)
                        high_list.append(high)
                mod= pd.concat(mod_list)
                high= pd.concat(high_list)
                mod.to_csv(output[0], sep= '\t', header= True, index= False)
                high.to_csv(output[1], sep= '\t', header= True, index= False)

rule GNOMAD_enrichment:
        ''
        input:
                '/mnt/work/pol/ROH/results/NC_{sample}_cox_spont',
                '/mnt/work/pol/ROH/GNOMAD/annotation/GNOMAD_{sample}_NC_{consequence}.txt',
                '/mnt/work/pol/ROH/results/HC_{sample}_cox_spont',
                '/mnt/work/pol/ROH/GNOMAD/annotation/GNOMAD_{sample}_HC_{consequence}.txt'
        output:
                '/mnt/work/pol/ROH/results/enrichment/GNOMAD_{sample}_{consequence}.txt'
        run:
                NC= pd.read_csv(input[0], sep= '\t', header= 0)
                NCr= pd.read_csv(input[1], sep= '\t', header= 0)
                HC= pd.read_csv(input[2], sep= '\t', header= 0)
                HCr= pd.read_csv(input[3], sep= '\t', header= 0)

                NC[['chr', 'cM1', 'cM2']]= NC['segment'].str.split(':', expand=True)
                HC[['chr', 'cM1', 'cM2']]= HC['segment'].str.split(':', expand=True)
                NC[['chr', 'cM1', 'cM2']]= NC[['chr', 'cM1', 'cM2']].astype(float)
                HC[['chr', 'cM1', 'cM2']]= HC[['chr', 'cM1', 'cM2']].astype(float)
                d= pd.merge(NC, NCr, on= ['chr', 'pos1', 'pos2'])
                df= pd.merge(HC, HCr, on= ['chr', 'pos1', 'pos2'])
                x_NC= d.groupby(['segment', 'chr', 'cM1', 'cM2']).size().to_frame('count').reset_index()
                x_HC= df.groupby(['segment', 'chr', 'cM1', 'cM2']).size().to_frame('count').reset_index()
                x_NC['prop']= x_NC.count / (x_NC.cM2 - x_NC.cM1)
                x_HC['prop']= x_HC.count / (x_HC.cM2 - x_HC.cM1)
                x_HC['zscore_GNOMAD']= (x_HC['prop']  - x_NC['prop'].mean()) / x_NC['prop'].std()
                x_HC['pvalue_GNOMAD']= st.norm.cdf(-(x_HC['zscore_GNOMAD']))
                x_HC.to_csv(output[0], sep= '\t', index= False, header= True, columns= ['segment', 'zscore_GNOMAD', 'pvalue_GNOMAD'])

