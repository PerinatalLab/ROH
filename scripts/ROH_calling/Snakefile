import pandas as pd
import numpy as np
import os
import gzip
from functools import reduce

cohort_nms= ['harvestm12', 'harvestm24','rotterdam1', 'rotterdam2', 'normentfeb', 'normentmay']
smpl_nms= ['maternal','paternal', 'fetal']
batch_nms= ['m12', 'm24']
CHR_nms= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12 ,13 ,14 ,15 ,16 ,17 ,18 ,19 ,20 ,21 ,22]

# Other arguments:

pruning_nms= ['none', 'soft', 'moderate']

dens_nms= [5]
SNP_nms= [15, 25, 50, 75, 100, 150, 200, 300, 400]
length_nms= [0.0000001]
het_nms= [0, 1]
GAP_nms= [5]

dens_bp= [5000]
SNP_bp= [15, 25, 50, 75, 100, 150, 200, 300, 400]
length_bp= [0.0000001]
het_bp= [0, 1]
GAP_bp= [5000]

# Functions

def isfloat(str):
    try:
        float(str)
        return True
    except ValueError:
        return False

def absOverlap(start0, end0, start1, end1):
        return (np.maximum(0, np.minimum(end0, end1) - np.maximum(start0, start1)))

rule copy_harvest_genotyped:
        ''
        input:
                expand('/mnt/archive/HARVEST/delivery-fhi/data/genotyped/m12/m12-genotyped.{ext}', ext= ['bed', 'bim', 'fam']),
                expand('/mnt/archive/HARVEST/delivery-fhi/data/genotyped/m24/m24-genotyped.{ext}', ext= ['bed', 'bim', 'fam'])
        output:
                temp(expand('/mnt/work/pol/ROH/harvestm12/genotypes/temp/harvestm12_genotyped.{ext}', ext= ['bed', 'bim', 'fam'])),
                temp(expand('/mnt/work/pol/ROH/harvestm24/genotypes/temp/harvestm24_genotyped.{ext}', ext= ['bed', 'bim', 'fam']))
        shell:
                '''
                cp {input[0]} {output[0]}; cp {input[1]} {output[1]}; cp {input[2]} {output[2]}
                cp {input[3]} {output[3]}; cp {input[4]} {output[4]}; cp {input[5]} {output[5]}
                '''

rule copy_rott_genotyped:
        'Copy genotype PLINK files and change name.'
        input:
                expand('/mnt/archive/ROTTERDAM1/delivery-fhi/data/genotyped/genotyped.{ext}', ext= ['bed', 'bim', 'fam']),
                expand('/mnt/archive/ROTTERDAM2/delivery-fhi/data/genotyped/genotyped.{ext}', ext= ['bed', 'bim', 'fam'])
        output:
                temp(expand('/mnt/work/pol/ROH/rotterdam1/genotypes/temp/rotterdam1_genotyped.{ext}', ext= ['bed', 'bim', 'fam'])),
                temp(expand('/mnt/work/pol/ROH/rotterdam2/genotypes/temp/rotterdam2_genotyped.{ext}', ext= ['bed', 'bim', 'fam'])),
        shell:
                '''
                cp {input[0]} {output[0]}; cp {input[1]} {output[1]}; cp {input[2]} {output[2]}
                cp {input[3]} {output[3]}; cp {input[4]} {output[4]}; cp {input[5]} {output[5]}
                '''

rule copy_norment_genotyped:
        'Copy genotype PLINK files and change name.'
        input:
                expand('/mnt/archive/NORMENT1/delivery-fhi/data/genotyped/feb18/genotyped.{ext}', ext= ['bed', 'bim', 'fam']),
                expand('/mnt/archive/NORMENT1/delivery-fhi/data/genotyped/may16/genotyped.{ext}', ext= ['bed', 'bim', 'fam'])
        output:
                temp(expand('/mnt/work/pol/ROH/normentfeb/genotypes/temp/normentfeb_genotyped.{ext}', ext= ['bed', 'bim', 'fam'])),
                temp(expand('/mnt/work/pol/ROH/normentmay/genotypes/temp/normentmay_genotyped.{ext}', ext= ['bed', 'bim', 'fam']))
        shell:
                '''
                cp {input[0]} {output[0]}; cp {input[1]} {output[1]}; cp {input[2]} {output[2]}
                cp {input[3]} {output[3]}; cp {input[4]} {output[4]}; cp {input[5]} {output[5]}
                '''

rule exclude_non_biallelic:
        'Set range file for multi-allelic SNPs.'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped.bim'
        output:
                temp('/mnt/work/pol/ROH/{cohort}/multiallelic.txt')
        run:
                d= pd.read_csv(input[0], sep= '\t', header= None)
                d.columns= ['chr', 'SNP', 'X', 'pos', 'A1', 'A2']
                d= d[d[['chr', 'pos']].duplicated(keep=False)]
                d= d[['chr', 'pos', 'pos', 'X']]
                d.to_csv(output[0], sep= '\t', header= False, index= False)

rule split_bed:
	'Modify the bed file: remove CHR 23, 24, 25 and 26, maf <=0.05 and split file by sample.'
	input:
		expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped.{ext}', ext= ['bed','bim','fam']),
		'/mnt/work/pol/ROH/{cohort}/pheno/{sample}_ids.txt',
		'/mnt/work/pol/ROH/{cohort}/multiallelic.txt'
	output:
		temp(expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log']))
	params:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped',
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped_{sample}'
	shell:
		'~/soft/plink --bfile {params[0]} --exclude range {input[4]} --maf 0.05 --keep {input[3]} --make-bed --chr 1-22 --make-founders --out {params[1]}'

rule freq_plink:
	''
	input:
		expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log'])
	output:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/genotyped_{sample}.frq'
	params:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped_{sample}',
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/genotyped_{sample}'
	shell:
		'''
		~/soft/plink --bfile {params[0]} --freq --out {params[1]}
		'''

rule format_freq:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/genotyped_{sample}.frq'
	output:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/maf_genotyped_{sample}.freq'
	run:
		d= pd.read_csv(input[0], header= 0, delim_whitespace=True)
		d['P']= 1 - d.MAF
		d.to_csv(output[0], header= True, index= False, sep= '\t')

rule multi_clumping:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/maf_genotyped_{sample}.freq',
		expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log'])
	output:
#		temp('/mnt/work/pol/ROH/{cohort}/genotypes/temp/soft/{cohort}_genotyped_{sample}.clumped'),
#                temp('/mnt/work/pol/ROH/{cohort}/genotypes/temp/moderate/{cohort}_genotyped_{sample}.clumped'),
#                temp('/mnt/work/pol/ROH/{cohort}/genotypes/temp/hard/{cohort}_genotyped_{sample}.clumped')
	params:
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped_{sample}',
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/soft/{cohort}_genotyped_{sample}',
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/moderate/{cohort}_genotyped_{sample}',
		'/mnt/work/pol/ROH/{cohort}/genotypes/temp/hard/{cohort}_genotyped_{sample}'
	shell:
		'''
		~/soft/plink --bfile {params[0]} --out {params[1]} --clump {input[0]} --clump-p1 1 --clump-p2 1 --clump-kb 250 --clump-r2 0.9
		~/soft/plink --bfile {params[0]} --out {params[2]} --clump {input[0]} --clump-p1 1 --clump-p2 1 --clump-kb 250 --clump-r2 0.5
		~/soft/plink --bfile {params[0]} --out {params[3]} --clump {input[0]} --clump-p1 1 --clump-p2 1 --clump-kb 250 --clump-r2 0.1
		'''

rule multi_pruning:
        'Filter PLINK file according to different pruning parameters.'
        input:
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log'])
        output:
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/soft/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['prune.out','prune.in', 'log'])),
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/moderate/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['prune.out','prune.in', 'log'])),
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/hard/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['prune.out','prune.in', 'log']))
        params:
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/soft/{cohort}_genotyped_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/moderate/{cohort}_genotyped_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/hard/{cohort}_genotyped_{sample}'
        shell:
                """
                ~/soft/plink --bfile {params[0]} --indep-pairwise 50 5 0.9 --out {params[1]}
                ~/soft/plink --bfile {params[0]} --indep-pairwise 50 5 0.5 --out {params[2]}
                ~/soft/plink --bfile {params[0]} --indep-pairwise 50 5 0.1 --out {params[3]}
                """

rule move_none_pruning:
        'Move PLINK files not pruned to wildcard.pruning == none folder.'
        input:
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed','bim','fam'])
        output:
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/none/pruned{{cohort}}_{{sample}}.{ext}', ext= ['bed','bim','fam'])
        params:
                '/mnt/work/pol/ROH/{cohort}/genotypes/none/'
        shell:
                """
                mkdir -p {params[0]}
                cp {input[0]} {output[0]}
                cp {input[1]} {output[1]}
                cp {input[2]} {output[2]}
                """

rule plink_bfile_prune:
        'Exclude genetic variants in prune.out files (obtained with rule plink_split_bed).'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/hard/{cohort}_genotyped_{sample}.prune.out',
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/soft/{cohort}_genotyped_{sample}.prune.out',
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/moderate/{cohort}_genotyped_{sample}.prune.out',
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/temp/{{cohort}}_genotyped_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam'])
        output:
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/hard/pruned{{cohort}}_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log']),
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/soft/pruned{{cohort}}_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log']),
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/moderate/pruned{{cohort}}_{{sample}}.{ext}', ext= ['bed', 'bim', 'fam', 'log'])
        params:
                '/mnt/work/pol/ROH/{cohort}/genotypes/temp/{cohort}_genotyped_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/hard/pruned{cohort}_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/soft/pruned{cohort}_{sample}',
                '/mnt/work/pol/ROH/{cohort}/genotypes/moderate/pruned{cohort}_{sample}'
        shell:
                '''
                ~/soft/plink --bfile {params[0]} --exclude {input[0]} --make-bed --out {params[1]}
                ~/soft/plink --bfile {params[0]} --exclude {input[1]} --make-bed --out {params[2]}
                ~/soft/plink --bfile {params[0]} --exclude {input[2]} --make-bed --out {params[3]}
                '''

rule replace_bp_cm:
        'PLINK cannot use cM to estimate ROH length, so we replace bp position to cM in the .bim file.'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_{sample}.bim',
                '/mnt/work/pol/ROH/1KG/1000GP_Phase3/genetic_map_combined_b37.txt'
        output:
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/cm_pruned{cohort}_{sample}.bim'
        run:
                d= pd.read_csv(input[0], sep= '\t', header= None)
                d.columns= ['chr', 'SNP', 'X', 'pos', 'A1', 'A2']
                g= pd.read_csv(input[1], delim_whitespace= True, header= 0, names= ['chr', 'pos', 'rate', 'cM'])
                g= g[['chr', 'cM', 'pos']]
#                g.columns= ['chr', 'Genetic_Map(cM)', 'pos']
                df= pd.merge(d, g, on= ['chr', 'pos'], how= 'left')
                df_miss= df.loc[df['cM'].isna(), :]
                newdf= pd.DataFrame()
                for CHR in set(df_miss.chr):
                        df_temp= df_miss.loc[df_miss.chr== CHR, :]
                        g_temp= g.loc[g.chr== CHR, :]
                        df_temp['newX']= np.interp(df_temp['pos'], g_temp['pos'], g_temp['cM'])
                        newdf= newdf.append(df_temp)
                newdf= newdf[['chr','pos', 'newX']]
                df= pd.merge(df, newdf, on= ['chr', 'pos'], how= 'left')
                df['X']= np.where(df['cM'].isna(), df['newX'], df['cM'])
                df['X']= (df.X*10**4).round() * 100
                df['X']= df['X'] + df.groupby(['chr', 'X']).cumcount()
                df[['pos', 'X']]= df[['X','pos']]
                df= df[['chr', 'SNP', 'X', 'pos', 'A1', 'A2']]
		df.sort_values(['chr', 'pos'], ascending= True, inplace= True)
                df.to_csv(output[0], sep= '\t', header= False, index= False)

rule run_ROH_multi_arg:
        'Estimate ROH using multiple arguments.'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.bed',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/cm_pruned{cohort}_fetal.bim',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.fam'
        output:
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/multi/{{pruning}}_fetaltemp_{{dens}}_{{SNP}}_{{length}}_{{het}}_{{GAP}}.{ext}', ext= ['log', 'hom', 'hom.summary'])),
                '/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
        params:
                '/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}'
        run:
                SNPwm= round(float(wildcards.SNP) * 0.05)
                GAP= int(float(wildcards.GAP) * 1000)
                dens= int(float(wildcards.dens) * 1000)
                shell("/home/pol.sole.navais/soft/plink --bed {input[0]} --bim {input[1]} --fam {input[2]} --homozyg-window-snp {wildcards.SNP} --homozyg-snp {wildcards.SNP} --homozyg-kb 0.0000001 --homozyg-gap {GAP} --homozyg-window-missing {SNPwm} --homozyg-window-threshold 0.0005 --homozyg-window-het {wildcards.het} --homozyg-density {dens} --out {params[0]}")

rule run_ROH_multi_arg_bp:
        'Estimate ROH using multiple arguments.'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.bed',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.bim',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.fam'
        output:
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/multi/{{pruning}}_bpfetaltemp_{{densbp}}_{{SNPbp}}_{{lengthbp}}_{{hetbp}}_{{GAPbp}}.{ext}', ext= ['log', 'hom.summary'])),
                '/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetaltemp_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.hom.indiv',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetaltemp_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.hom'
        params:
                '/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetaltemp_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}'
        run:
                SNPwm= round(float(wildcards.SNPbp) * 0.05)
                shell("/home/pol.sole.navais/soft/plink --bed {input[0]} --bim {input[1]} --fam {input[2]} --homozyg-window-snp {wildcards.SNPbp} --homozyg-snp {wildcards.SNPbp} --homozyg-kb {wildcards.lengthbp} --homozyg-gap {wildcards.GAPbp} --homozyg-window-missing {SNPwm} --homozyg-window-threshold 0.0005 --homozyg-window-het {wildcards.hetbp} --homozyg-density {wildcards.densbp} --out {params[0]}")

rule remove_gap_multiple_ROH_cM:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}.hom',
		'/mnt/work/pol/ROH/1KG/cm_UCSC_gap.txt',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
	output:
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
	run:
		df= pd.read_csv(input[1], header= 0, sep= '\t')
		df_list= list()
		for d in pd.read_csv(input[0], header= 0, delim_whitespace= True, chunksize= 10**5, iterator= True):
			for chrom in set(d.CHR):
				temp_d= d.loc[d.CHR== chrom, :]
				temp_df= df.loc[df.chr==chrom, :]
				temp_d= pd.merge(temp_d, temp_df, left_on= 'CHR', right_on= 'chr')
				temp_d= temp_d.loc[(temp_d.POS1 > temp_d.cM2 * 10**6) | (temp_d.POS2< temp_d.cM1 * 10**6), :]
				temp_d.drop_duplicates(subset= ['IID', 'CHR', 'POS1', 'POS2'], inplace=True, keep= 'first')
				temp_d= temp_d[['IID', 'CHR', 'POS1', 'POS2', 'KB']]
				df_list.append(temp_d)
		d= pd.concat(df_list)
		d.to_csv(output[0], index= False, header= True, sep= '\t')
		df= d.groupby('IID')['KB'].agg(['mean', 'sum', 'count']).reset_index()
		df.columns= ['IID', 'KBAVG', 'KB', 'NSEG']
		x= pd.read_csv(input[2], header= 0, delim_whitespace= True, usecols= ['IID'])
		df= pd.merge(df, x, on= 'IID', how= 'outer')
		df.fillna(0, inplace= True)
		df.to_csv(output[1], sep= '\t', header= True, index=False)

rule filter_sUPD_ROH_opt_cM:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom',
		'/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/cm_pruned{cohort}_fetal.bim',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
	output:
		'/mnt/work/pol/ROH/{cohort}/multi/list_{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.txt'
	run:
		d_cm= pd.read_csv(input[0], delim_whitespace= True, header= 0)
		d_cm= d_cm.groupby(['IID', 'CHR'])['KB'].agg('sum').reset_index()
		CHROM= pd.read_csv(input[1], header= None, delim_whitespace= True, names= ['CHR', 'snp', 'X', 'cM', 'A1', 'A2'], usecols= ['CHR', 'cM'])
		CHROM['cMd']= CHROM.groupby(['CHR'])['cM'].diff(1)
		CHROM= CHROM.groupby('CHR')['cMd'].agg('sum').reset_index()
		d_cm= pd.merge(d_cm, CHROM, on= ['CHR'])
		d_cm= d_cm.loc[((d_cm.KB * 1000) / d_cm.cMd) > 0.70, :]
		cM= sum(CHROM.cMd)
		x= pd.read_csv(input[2], header= 0, delim_whitespace= True)
		x['FKB']= x['KB'] * 1000 / cM
		x= x.loc[x.FKB>= 0.08, :]
		d_cm= pd.concat([d_cm[['IID', 'KB']], x[['IID', 'KB']]])
		d_cm.to_csv(output[0], sep= '\t', header= False, index= False, columns= ['IID'])

rule remove_gap_multiple_ROH_bp:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}.hom',
		'/mnt/work/pol/refdata/UCSC_gap.txt',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetaltemp_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
	output:
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv'
	run:
		d= pd.read_csv(input[0], header= 0, delim_whitespace= True)
		df= pd.read_csv(input[1], header= 0, sep= '\t', names=['chr', 'start', 'end', 'size', 'type'])
		df_list= list()
		for d in pd.read_csv(input[0], header= 0, delim_whitespace= True, chunksize= 10**5, iterator= True):
                        for chrom in set(d.CHR):
                                temp_d= d.loc[d.CHR== chrom, :]
                                temp_df= df.loc[df.chr==chrom, :]
                                temp_d= pd.merge(temp_d, temp_df, left_on= 'CHR', right_on= 'chr')
                                temp_d= temp_d.loc[(temp_d.POS1 > temp_d.end) | (temp_d.POS2< temp_d.start), :]
                                temp_d.drop_duplicates(subset= ['IID', 'CHR', 'POS1', 'POS2'], inplace=True, keep= 'first')
                                temp_d= temp_d[['IID', 'CHR', 'POS1', 'POS2', 'KB']]
                                df_list.append(temp_d)
		d= pd.concat(df_list)
                d.to_csv(output[0], index= False, header= True, sep= '\t')
                df= d.groupby('IID')['KB'].agg(['mean', 'sum', 'count']).reset_index()
                df.columns= ['IID', 'KBAVG', 'KB', 'NSEG']
		x= pd.read_csv(input[2], header= 0, delim_whitespace= True, usecols= ['IID'])
                df= pd.merge(df, x, on= 'IID', how= 'outer')
                df.fillna(0, inplace= True)
                df.to_csv(output[1], sep= '\t', header= True, index=False)

rule filter_sUPD_ROH_opt_bp:
        ''
        input:
                '/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetal_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.hom',
		'/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_fetal.bim',
		'/mnt/work/pol/ROH/{cohort}/multi/{pruning}_bpfetal_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.hom.indiv'
        output:
                '/mnt/work/pol/ROH/{cohort}/multi/list_{pruning}_bpfetal_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.txt'
        run:
                d_bp= pd.read_csv(input[0], delim_whitespace= True, header= 0)
                d_bp= d_bp.groupby(['IID', 'CHR'])['KB'].agg('sum').reset_index()
                CHROM= pd.read_csv(input[1], header= None, delim_whitespace= True, names= ['CHR', 'snp', 'X', 'bp', 'A1', 'A2'], usecols= ['CHR', 'bp'])
		CHROM['bpd']= CHROM.groupby('CHR')['bp'].diff(1)
		CHROM= CHROM.groupby('CHR')['bpd'].agg('sum').reset_index()
		d_bp= pd.merge(d_bp, CHROM, on= ['CHR'])
                d_bp= d_bp.loc[((d_bp.KB * 1000) / d_bp.bpd) > 0.70, :]
		bp= sum(CHROM.bpd)
		x= pd.read_csv(input[2], header= 0, delim_whitespace= True)
		x['FKB']= (x['KB'] * 1000) / bp
		x= x.loc[x.FKB>= 0.08, :]
		d_bp= pd.concat([d_bp[['IID', 'KB']], x[['IID', 'KB']]])
                d_bp.to_csv(output[0], sep= '\t', header= False, index= False, columns= ['IID'])


rule determine_arguments_ROH:
        'Determine ROH estimation arguments that maximise ROH - parental IBD correlation.'
        input:
                '/mnt/work/pol/{cohort}/pca/{cohort}_pca.txt',
                '/mnt/work/pol/ROH/{cohort}/ibd/to_phase.fam',
                '/mnt/work/pol/ROH/{cohort}/genotypes/none/pruned{cohort}_fetal.fam',
                '/mnt/work/pol/ROH/{cohort}/ibd/parental_ibd.txt',
                '/mnt/work/pol/{cohort}/pheno/flag_list.txt',
                '/mnt/work/pol/ROH/{cohort}/pheno/{cohort}_trios.txt',
                '/mnt/work/pol/{cohort}/relatedness/all_{cohort}.kin0',
                '/mnt/work/pol/{cohort}/pca/pca_exclude.txt',
		'/mnt/work/pol/{cohort}/pheno/{cohort}_mfr.csv',
		'/mnt/work/pol/{cohort}/pheno/{cohort}_linkage.csv',
		expand('/mnt/work/pol/ROH/{{cohort}}/multi/list_{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.txt', dens= dens_nms, SNP= SNP_nms, length= length_nms, het= het_nms, GAP= GAP_nms, pruning= pruning_nms),
		expand('/mnt/work/pol/ROH/{{cohort}}/multi/list_{pruning}_bpfetal_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.txt', densbp= dens_bp, SNPbp= SNP_bp, lengthbp= length_bp, hetbp= het_bp, GAPbp= GAP_bp, pruning= pruning_nms),
                expand('/mnt/work/pol/ROH/{{cohort}}/multi/{pruning}_fetal_{dens}_{SNP}_{length}_{het}_{GAP}.hom.indiv', dens= dens_nms, SNP= SNP_nms, length= length_nms, het= het_nms, GAP= GAP_nms, pruning= pruning_nms),
		expand('/mnt/work/pol/ROH/{{cohort}}/multi/{pruning}_bpfetal_{densbp}_{SNPbp}_{lengthbp}_{hetbp}_{GAPbp}.hom.indiv', densbp= dens_bp, SNPbp= SNP_bp, lengthbp= length_bp, hetbp= het_bp, GAPbp= GAP_bp, pruning= pruning_nms)
        output:
                '/mnt/work/pol/ROH/arguments/arg_R2_{cohort}.txt',
                '/mnt/work/pol/ROH/arguments/max_R2_{cohort}.txt'
        script:
                'R2_ROH_IBD.R'

rule estimate_ROH:
        '''
        Obtain ROH estimates using PLINK 1.9.
        Configuration according to file "/mnt/work/pol/ROH/arguments/max_R2.txt"
        '''
        input:
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/{pruning}/pruned{{cohort}}_{{sample}}.{ext}', pruning= pruning_nms, ext= ['bed', 'bim', 'fam']),
                expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/{pruning}/cm_pruned{{cohort}}_{{sample}}.bim', pruning= pruning_nms),
                '/mnt/work/pol/ROH/arguments/max_R2_{cohort}.txt'
        output:
                '/mnt/work/pol/ROH/{cohort}/runs/tmp_{cohort}_{sample}.hom.indiv',
                '/mnt/work/pol/ROH/{cohort}/runs/tmp_{cohort}_{sample}.hom',
                '/mnt/work/pol/ROH/{cohort}/runs/{sample}_input_ROH_geno.txt',
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/runs/tmp_{{cohort}}_{{sample}}.{ext}', ext= ['log', 'hom.summary']))
        params:
                '/mnt/work/pol/ROH/{cohort}/runs/tmp_{cohort}_{sample}'
        run:
                maxim= [df for df in input if 'max_R2' in df]
                parlist= [line.strip() for line in open("".join(maxim), 'r')]
                parlist= [float(x) for x in parlist]
                if parlist[0]== 0:
                        prun= 'none'
                if parlist[0]== 1:
                        prun= 'soft'
                if parlist[0]== 2:
                        prun= 'moderate'
                if parlist[0]== 3:
                        prun= 'hard'
                bed= [bed for bed in input if prun in bed and 'bed' in bed]
                fam= [fam for fam in input if prun in fam and 'fam' in fam]
                GAP= round(parlist[5] * 1000)
                SNPwm= round(parlist[2] * 0.05)
                dens= round(parlist[1] * 1000)
                if parlist[1] < 100:
                        bim= [bim for bim in input if prun in bim and 'bim' in bim and 'cm' in bim]
                        shell("/home/pol.sole.navais/soft/plink --bed {bed} --bim {bim} --fam {fam} --homozyg-window-snp {parlist[2]} --homozyg-snp {parlist[2]} --homozyg-kb {parlist[3]} --homozyg-gap {GAP} --homozyg-window-missing {SNPwm} --homozyg-window-threshold 0.0005 --homozyg-window-het {parlist[4]} --homozyg-density {dens} --out {params}")
                if parlist[1] > 100:
                        bim= [bim for bim in input if prun in bim and 'bim' in bim and 'cm' not in bim]
                        shell("/home/pol.sole.navais/soft/plink --bed {bed} --bim {bim} --fam {fam} --homozyg-window-snp {parlist[2]} --homozyg-snp {parlist[2]} --homozyg-kb {parlist[3]} --homozyg-gap {parlist[5]} --homozyg-window-missing {SNPwm} --homozyg-window-threshold 0.0005 --homozyg-window-het {parlist[4]} --homozyg-density {parlist[1]} --out {params}")
                l= list(["".join(bed), "".join(bim), "".join(fam)])
                with open(output[2], 'w') as f:
                        f.writelines( "%s\n" % item for item in l)

rule gap_ROH:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/runs/tmp_{cohort}_{sample}.hom',
		'/mnt/work/pol/ROH/1KG/cm_UCSC_gap.txt',
		'/mnt/work/pol/ROH/{cohort}/runs/tmp_{cohort}_{sample}.hom.indiv'
	output:
		'/mnt/work/pol/ROH/{cohort}/runs/{cohort}_{sample}.hom',
		'/mnt/work/pol/ROH/{cohort}/runs/{cohort}_{sample}.hom.indiv'
	run:
		df= pd.read_csv(input[1], header= 0, sep= '\t')
		df_list= list()
		for d in pd.read_csv(input[0], header= 0, delim_whitespace= True, chunksize= 10**5, iterator= True):
			for chrom in set(d.CHR):
				temp_d= d.loc[d.CHR== chrom, :]
				temp_df= df.loc[df.chr==chrom, :]
				temp_d= pd.merge(temp_d, temp_df, left_on= 'CHR', right_on= 'chr')
				temp_d= temp_d.loc[(temp_d.POS1 > temp_d.cM2 * 10**8) | (temp_d.POS2< temp_d.cM1 * 10**6), :]
				temp_d.drop_duplicates(subset= ['IID', 'CHR', 'POS1', 'POS2'], inplace=True, keep= 'first')
				temp_d= temp_d[['IID', 'CHR', 'POS1', 'POS2', 'KB']]
				df_list.append(temp_d)
		d= pd.concat(df_list)
		d.to_csv(output[0], index= False, header= True, sep= '\t')
		df= d.groupby('IID')['KB'].agg(['mean', 'sum', 'count']).reset_index()
		df.columns= ['IID', 'KBAVG', 'KB', 'NSEG']
		x= pd.read_csv(input[2], header= 0, delim_whitespace= True, usecols= ['IID'])
                df= pd.merge(df, x, on= 'IID', how= 'outer')
                df.fillna(0, inplace= True)
		df.to_csv(output[1], sep= '\t', header= True, index=False)

rule list_sUPD_ROH:
	''
	input:
		'/mnt/work/pol/ROH/{cohort}/runs/{cohort}_{sample}.hom',
		expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/{pruning}/pruned{{cohort}}_{{sample}}.bim', pruning= pruning_nms),
		expand('/mnt/work/pol/ROH/{{cohort}}/genotypes/{pruning}/cm_pruned{{cohort}}_{{sample}}.bim', pruning= pruning_nms),
		'/mnt/work/pol/ROH/arguments/max_R2_{cohort}.txt'
	output:
		'/mnt/work/pol/ROH/{cohort}/runs/sUPD_{cohort}_{sample}.txt'
	run:
		maxim= [df for df in input if 'max_R2' in df]
		parlist= [line.strip() for line in open("".join(maxim), 'r')]
		parlist= [float(x) for x in parlist]
		if parlist[0]== 0:
			prun= 'none'
		if parlist[0]== 1:
			prun= 'soft'
		if parlist[0]== 2:
			prun= 'moderate'
		if parlist[0]== 3:
			prun= 'hard'
		if parlist[1] < 100:
			bim= [bim for bim in input if prun in bim and 'bim' in bim and 'cm' in bim]
		if parlist[1] > 100:
			bim= [bim for bim in input if prun in bim and 'bim' in bim and 'cm' not in bim]
		d_cm= pd.read_csv(input[0], delim_whitespace= True, header= 0)
		d_cm= d_cm.groupby(['IID', 'CHR'])['KB'].agg('sum').reset_index()
		CHROM= pd.read_csv("".join(bim), delim_whitespace= True, header= 0, names= ['CHR', 'snp', 'X', 'cm', 'A1', 'A2'], usecols= ['CHR', 'cm'])
		CHROM['cmd']= CHROM.groupby('CHR')['cm'].diff(1)
		CHROM= CHROM.groupby('CHR')['cmd'].agg('sum').reset_index()
		d_cm= pd.merge(d_cm, CHROM, on= ['CHR'])
		d_cm= d_cm.loc[((d_cm.KB / 1000) / d_cm.cmd) > 0.70, :]
		d_cm.to_csv(output[0], sep= '\t', header= False, index= False, columns= ['IID'])


rule excess_homozygosity:
        'Compute excess homozygosity using PLINK --het flag.'
        input:
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_{sample}.bed',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_{sample}.bim',
                '/mnt/work/pol/ROH/{cohort}/genotypes/{pruning}/pruned{cohort}_{sample}.fam'
        output:
                temp(expand('/mnt/work/pol/ROH/{{cohort}}/results/het/{{pruning}}_excess_hom_{{sample}}.{ext}', ext= ['het', 'log']))
        params:
                '/mnt/work/pol/ROH/{cohort}/results/het/{pruning}_excess_hom_{sample}'
        shell:
                '~/soft/plink --bed {input[0]} --bim {input[1]} --fam {input[2]} --het --out {params[0]}'

rule merge_homozygosity:
        'Merge excess homozygosity from different pruning.'
        input:
                expand('/mnt/work/pol/ROH/{{cohort}}/results/het/{pruning}_excess_hom_{{sample}}.het', pruning= pruning_nms)
        output:
                '/mnt/work/pol/ROH/{cohort}/results/het/{sample}_excess_hom.txt'
        run:
                dflist= list()
                for i in input:
                        d= pd.read_csv(i, delim_whitespace=True, header=0)
                        d= d[['IID', 'F']]
                        if 'none' in i: d.columns= ['IID', 'none_F']
                        if 'soft' in i: d.columns= ['IID', 'soft_F']
                        if 'moderate' in i: d.columns= ['IID', 'moderate_F']
                        if 'hard' in i: d.columns= ['IID', 'hard_F']
                        dflist.append(d)
                d= reduce(lambda x, y: pd.merge(x, y, on= 'IID'), dflist)
                d.to_csv(output[0], index=False, header= True, sep= '\t')


